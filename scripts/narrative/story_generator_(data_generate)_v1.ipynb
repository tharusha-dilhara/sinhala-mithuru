{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58723,
     "status": "ok",
     "timestamp": 1766485688501,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "p6_NGrkkS9hF",
    "outputId": "daa0d68b-2836-4a33-ba89-0d64d5ff9dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 'project_root': The main folder containing the entire application structure.\n",
    "project_root = '/content/drive/MyDrive/story_generation_comprehension'\n",
    "\n",
    "# 'dataset_path': Specific location where the generated synthetic data will be stored.\n",
    "dataset_path = os.path.join(project_root, 'story_generator', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1766485709760,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "8m4UXhJnbDK5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Ensure the project root is in the system path so we can import modules from 'app/src'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWMrqrmKcchS"
   },
   "source": [
    "## Generate synthatic game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1766485713190,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "B0oIDd8vayC_"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_SAMPLES = 100000 # Adjust the number of data points you want to generate\n",
    "MAX_ROUNDS = 9\n",
    "MAX_ROUNDS_mark = MAX_ROUNDS*100  # Maximum rounds per level\n",
    "MAX_SCORE_RANGE = 100  # Maximum score (XP) range\n",
    "MAX_TIME_FOR_MAX_SCORE = 10*60  # Maximum time (second) for achieving max score\n",
    "game_level=15\n",
    "max_engagement_time=15*60 #second\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data():\n",
    "    data = []\n",
    "    start_time = datetime(2025, 11, 1, 8, 0, 0)\n",
    "\n",
    "    for i in range(NUM_SAMPLES):\n",
    "        timestamp = start_time + timedelta(minutes=random.randint(1, 720))\n",
    "        game_level = random.randint(1, 15)\n",
    "         # Adjust max rounds based on game level\n",
    "        success_count= random.randint(1, MAX_ROUNDS)\n",
    "        success_count_mark=random.randint(1, success_count*100)\n",
    "        attempt_count = random.randint(success_count, MAX_ROUNDS )\n",
    "        attempt_count_mark=attempt_count*100\n",
    "        engagement_time_total = sum([random.uniform(60, max_engagement_time) for _ in range(attempt_count)]) #all attend ,seconds\n",
    "\n",
    "        # Calculate the game score (XP) based on your logic\n",
    "        score_total_level = calculate_game_score(success_count_mark,attempt_count_mark, attempt_count,engagement_time_total , MAX_ROUNDS )\n",
    "\n",
    "        data.append([timestamp,success_count_mark,attempt_count,attempt_count_mark,score_total_level, game_level,engagement_time_total])\n",
    "\n",
    "        # Print progress\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"Generated {i + 1} samples\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2801,
     "status": "ok",
     "timestamp": 1766485752560,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "j9InSzSHbJyR",
    "outputId": "52bb653d-3e65-49cb-e9c9-0cda4ec92ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/drive/MyDrive/story_generation_comprehension/app/src/calculate_game_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /content/drive/MyDrive/story_generation_comprehension/app/src/calculate_game_score.py\n",
    "\n",
    "# Constants\n",
    "NUM_SAMPLES = 100000  # Adjust the number of data points you want to generate\n",
    "MAX_SCORE_RANGE = 100  # Maximum score (XP) range\n",
    "MAX_TIME_FOR_MAX_SCORE = 10*60  # Maximum time (second) for achieving max score\n",
    "game_level=15\n",
    "#max_engagement_time=360 #second\n",
    "\n",
    "\n",
    "# Function to calculate game score (XP) based on your logic\n",
    "def calculate_game_score(success_count_mark,attempt_count_mark, attempt_count, engagement_time_total, max_rounds):\n",
    "    # Calculate the maximum score based on your criteria\n",
    "    max_score = MAX_SCORE_RANGE\n",
    "\n",
    "    # Calculate the time threshold for achieving max score\n",
    "    #max_time_threshold = max(1, max_rounds / MAX_TIME_FOR_MAX_SCORE)\n",
    "    max_time_threshold_per_attend =engagement_time_total / attempt_count\n",
    "\n",
    "    # Calculate score based on your criteria\n",
    "    if success_count_mark == attempt_count_mark and max_time_threshold_per_attend  <= MAX_TIME_FOR_MAX_SCORE:\n",
    "        score = max_score\n",
    "    elif success_count_mark <= attempt_count_mark and max_time_threshold_per_attend  <= MAX_TIME_FOR_MAX_SCORE:\n",
    "        score = ((success_count_mark / attempt_count_mark) * max_score*0.5)+(max_score*0.5)\n",
    "\n",
    "    elif  success_count_mark <= attempt_count_mark and max_time_threshold_per_attend >= MAX_TIME_FOR_MAX_SCORE:\n",
    "        score = ((MAX_TIME_FOR_MAX_SCORE / max_time_threshold_per_attend) * max_score*0.5)+((success_count_mark / attempt_count_mark) * max_score*0.5)\n",
    "\n",
    "    score=min(score,max_score)\n",
    "\n",
    "    return int(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2402,
     "status": "ok",
     "timestamp": 1766485758853,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "7Al7DpgRhwpq",
    "outputId": "27d9186f-018d-4ff8-c229-a248112b1815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 'calculate_game_score' from app/src/\n"
     ]
    }
   ],
   "source": [
    "# Import the scoring function from the 'app.src' package.\n",
    "# We use a try-except block to handle potential path issues gracefully.\n",
    "try:\n",
    "    from app.src.calculate_game_score import calculate_game_score\n",
    "    print(\"Successfully imported 'calculate_game_score' from app/src/\")\n",
    "except ImportError as e:\n",
    "    print(f\" Import Failed: {e}\")\n",
    "    print(\"Hint: Ensure 'project_root' is correctly added to sys.path in Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2590,
     "status": "ok",
     "timestamp": 1766485770469,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "Tt9_gY8ubG34",
    "outputId": "c33ad65c-503f-4d53-d27d-e29ae6fe4f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 samples\n",
      "Generated 20000 samples\n",
      "Generated 30000 samples\n",
      "Generated 40000 samples\n",
      "Generated 50000 samples\n",
      "Generated 60000 samples\n",
      "Generated 70000 samples\n",
      "Generated 80000 samples\n",
      "Generated 90000 samples\n",
      "Generated 100000 samples\n",
      "Raw dataset saved to: /content/drive/MyDrive/story_generation_comprehension/story_generator/dataset/combined_game_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate the data\n",
    "combined_data = generate_synthetic_data()\n",
    "\n",
    "# 2. Convert to DataFrame\n",
    "columns = [\n",
    "    \"timestamp\", \"success_count_mark\", \"attempt_count\",\n",
    "    \"attempt_count_mark\", \"score_total_level\", \"game_level\", \"engagement_time_Total_sec\"\n",
    "]\n",
    "df = pd.DataFrame(combined_data, columns=columns)\n",
    "\n",
    "# 3. Save Raw Data\n",
    "raw_filename = \"combined_game_data.csv\"\n",
    "df.to_csv(raw_filename, index=False)\n",
    "print(f\"Raw dataset saved to: {os.path.join(dataset_path, raw_filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOgndx9RxJ7W"
   },
   "source": [
    "## calculate_improvement_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3584,
     "status": "ok",
     "timestamp": 1766485800422,
     "user": {
      "displayName": "Ishini Tecla",
      "userId": "11322021249840097510"
     },
     "user_tz": -330
    },
    "id": "OKh-9aY6xNg1",
    "outputId": "899fd1f2-7fde-40b2-d9f4-7a5ebe5449b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Improvement Scores...\n",
      "Final processed dataset saved to: /content/drive/MyDrive/story_generation_comprehension/story_generator/dataset/game_data_with_improvement.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_improvement_score(row):\n",
    "    \"\"\"\n",
    "    Computes a weighted improvement score (1-10) based on multiple factors:\n",
    "    Success Rate (30%), Attempts (20%), Level Difficulty (20%), Engagement Efficiency (30%).\n",
    "    \"\"\"\n",
    "    # Define max marks locally to ensure function is self-contained\n",
    "    MAX_ROUNDS_mark = 900\n",
    "\n",
    "    # 1. Normalize Factors (Scale 0-10)\n",
    "    norm_success = (row[\"success_count_mark\"] / MAX_ROUNDS_mark) * 10\n",
    "    norm_attempt = (1 - (row[\"attempt_count_mark\"] / MAX_ROUNDS_mark)) * 10\n",
    "    norm_level = (row[\"game_level\"] / 15) * 10\n",
    "\n",
    "    # Avoid division by zero\n",
    "    max_possible_time = (15 * 60) * row[\"attempt_count\"]\n",
    "    norm_engagement = (1 - (row[\"engagement_time_Total_sec\"] / max_possible_time)) * 10\n",
    "\n",
    "    # 2. Weighted Sum\n",
    "    improvement = (0.3 * norm_success) + (0.2 * norm_attempt) + (0.2 * norm_level) + (0.3 * norm_engagement)\n",
    "\n",
    "    # 3. Adjustment Factor (Reward high performance across all metrics)\n",
    "    adjustment = (norm_success + norm_attempt + norm_level - norm_engagement) / 4\n",
    "    improvement += adjustment\n",
    "\n",
    "    # 4. Clamp result between 1 and 10\n",
    "    return max(1, min(improvement, 10))\n",
    "\n",
    "# Apply the function\n",
    "print(\"Calculating Improvement Scores...\")\n",
    "df[\"improvement_score\"] = df.apply(calculate_improvement_score, axis=1)\n",
    "\n",
    "# Save Final Processed Data\n",
    "final_filename = \"game_data_with_improvement.csv\"\n",
    "df.to_csv(final_filename, index=False)\n",
    "print(f\"Final processed dataset saved to: {os.path.join(dataset_path, final_filename)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
